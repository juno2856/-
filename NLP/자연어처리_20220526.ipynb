{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리 20220526",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juno2856/deeplearning/blob/master/NLP/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_20220526.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# seq2seq 모델"
      ],
      "metadata": {
        "id": "q0MlIIp8wfZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"
      ],
      "metadata": {
        "id": "BYf-_1t1wiII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder 구현"
      ],
      "metadata": {
        "id": "SUO9UmWfwk2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-6.max-800x600.jpg)"
      ],
      "metadata": {
        "id": "lCPSBCPdwnNf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT83VDAopzxr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #( 변수 1, 변수 2) # 나는 밥을 먹었어\n",
        "        self.lstm = tf.keras.layers.LSTM(enc_units) #( 변수 3 )\n",
        "    \n",
        "    def call(self, x):\n",
        "        print(\"입력 shape :\", x.shape) # sample input // 춤 추는 소시지 \n",
        "\n",
        "        x = self.embedding(x)\n",
        "        print(\"Embedding Layer를 거친 shape :\", x.shape)\n",
        "\n",
        "        output = self.lstm(x)\n",
        "        print(\"LSTM shape의 output shape :\", output.shape)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "slWrhuY1wuw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30000\n",
        "emb_size = 256\n",
        "lstm_size = 512\n",
        "batch_size = 1\n",
        "sample_seq_len = 3\n",
        "\n",
        "print(\"Vocab Size : {0}\".format(vocab_size))\n",
        "print(\"Embedding Size : {0}\".format(emb_size))\n",
        "print(\"LSTM Size : {0}\".format(lstm_size))\n",
        "print(\"Batch_size : {0}\".format(batch_size))\n",
        "print(\"Sample Sequence Length : {0}\".format(sample_seq_len))"
      ],
      "metadata": {
        "id": "2mgOnbTXxCMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe9f5b7-f3df-4987-8593-9594c57e8c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size : 30000\n",
            "Embedding Size : 256\n",
            "LSTM Size : 512\n",
            "Batch_size : 1\n",
            "Sample Sequence Length : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_size, emb_size, lstm_size) #vocab_size, embedding_dim, enc_units):\n",
        "sample_input = tf.zeros((batch_size, sample_seq_len)) # 춤 추는 소시지\n",
        "\n",
        "sample_output = encoder(sample_input)"
      ],
      "metadata": {
        "id": "T0nOgRrexIzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1137980a-5a91-467f-c606-b8a623ab4460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 shape : (1, 3)\n",
            "Embedding Layer를 거친 shape : (1, 3, 256)\n",
            "LSTM shape의 output shape : (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder 구현"
      ],
      "metadata": {
        "id": "YaCFAU30xPMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"
      ],
      "metadata": {
        "id": "dFRBUyamxRYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #(변수 1, 변수 2)\n",
        "        self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True) #(변수 3, return_sequences=True) ####\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size) #(변수 4)\n",
        "        self.softmax = tf.keras.layers.Softmax(axis = -1) # None (변수 5)\n",
        "\n",
        "    def call(self, x, context_v):\n",
        "        print(\"입력 shape : \", x.shape)\n",
        "\n",
        "        x = self.embedding(x)   # (1,3,256)\n",
        "        print(\"Embedding layer를 거친 shape\", x.shape)\n",
        "\n",
        "        context_v = tf.repeat(tf.expand_dims(context_v, axis=1), repeats=x.shape[1], axis=1) # (1,512) -> (1,1,512)\n",
        "        x = tf.concat([x, context_v], axis= -1) # [변수 1, 변수 2], axis = -1)\n",
        "        print('Context Vector가 더해진 shape : ', x.shape)\n",
        "\n",
        "        x = self.lstm(x)\n",
        "        print(\"LSTM layer의 output layer : \", x.shape)\n",
        "\n",
        "        output = self.fc(x)\n",
        "        print(\"Decoder의 최종 ouput layer : \", output.shape)\n",
        "\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "QNPaQgSVxNvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30000\n",
        "emb_size = 256\n",
        "lstm_size = 512\n",
        "batch_size = 1\n",
        "sample_seq_len = 3\n",
        "\n",
        "print(\"Vocab Size : {0}\".format(vocab_size))\n",
        "print(\"Embedding Size : {0}\".format(emb_size))\n",
        "print(\"LSTM Size : {0}\".format(lstm_size))\n",
        "print(\"Batch_size : {0}\".format(batch_size))\n",
        "print(\"Sample Sequence Length : {0}\".format(sample_seq_len))"
      ],
      "metadata": {
        "id": "zmLtmubHxzyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a736321-b744-4721-9496-2babd276e1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size : 30000\n",
            "Embedding Size : 256\n",
            "LSTM Size : 512\n",
            "Batch_size : 1\n",
            "Sample Sequence Length : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(vocab_size, emb_size, lstm_size)\n",
        "sample_input = tf.zeros((batch_size, sample_seq_len)) # 춤 추는 소시지\n",
        "\n",
        "sample_output = decoder(sample_input, sample_output)"
      ],
      "metadata": {
        "id": "ZwalJJzKx0W-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908108eb-78a1-4b86-90f2-df83f3ee99bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 shape :  (1, 3)\n",
            "Embedding layer를 거친 shape (1, 3, 256)\n",
            "Context Vector가 더해진 shape :  (1, 3, 768)\n",
            "LSTM layer의 output layer :  (1, 3, 512)\n",
            "Decoder의 최종 ouput layer :  (1, 3, 30000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention\n",
        "https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c"
      ],
      "metadata": {
        "id": "I2rWe11Hyake"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bahdanau Attention\n",
        "$$ Score_{alignment} = W * tanh(W_{decoder} * H_{decoder} + W_{encoder} * H_{encoder}) $$"
      ],
      "metadata": {
        "id": "HVVLgiLHycqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "W2CJ2qliyaxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_decoder = tf.keras.layers.Dense(units)\n",
        "        self.w_encoder = tf.keras.layers.Dense(units)\n",
        "        self.w_combine = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, h_encoder, h_decoder):\n",
        "        print(\"[H_encoder] shape : \", h_encoder.shape)\n",
        "\n",
        "        h_encoder = self.w_encoder(h_encoder) # Wencoder∗Hencoder\n",
        "        print(\"[w_encoder x h_encoder] shape : \", h_encoder.shape)\n",
        "\n",
        "        print(\"\\n[H_decoder shape :\", h_decoder.shape)\n",
        "        h_decoder = tf.expand_dims(h_decoder, 1)\n",
        "        h_decoder = self.w_decoder(h_decoder)  # Wdecoder∗Hdecoder\n",
        "\n",
        "        print(\"[w_encoder x h_decoder] shape :\", h_decoder.shape)\n",
        "\n",
        "        score = self.w_combine(tf.nn.tanh(h_encoder+h_decoder)) # W\n",
        "        print(\"[score alinment] shape :\", score.shape)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis = -1)\n",
        "        print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n",
        "\n",
        "        context_vector = attention_weights * h_decoder\n",
        "        context_vector = tf.reduce_sum(context_vector, axis = 1) \n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "9csARr_vyftu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_size = 100\n",
        "print(\"hidden state {0}차원으로 Mapping \\n\".format(w_size))\n",
        "\n",
        "attention = BahdanauAttention(w_size)\n",
        "\n",
        "enc_state = tf.random.uniform((1, 10, 512)) # ex 한글 embedding value \n",
        "dec_state = tf.random.uniform((1, 512)) # ex  영어 embedding value\n",
        "\n",
        "_ = attention(enc_state, dec_state)"
      ],
      "metadata": {
        "id": "TdSyZrAnzUQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ffb23c-0a8a-4629-861a-a780f6b5240f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden state 100차원으로 Mapping \n",
            "\n",
            "[H_encoder] shape :  (1, 10, 512)\n",
            "[w_encoder x h_encoder] shape :  (1, 10, 100)\n",
            "\n",
            "[H_decoder shape : (1, 512)\n",
            "[w_encoder x h_decoder] shape : (1, 1, 100)\n",
            "[score alinment] shape : (1, 10, 1)\n",
            "\n",
            "최종 weight : \n",
            " [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GN-4-L-9.jpg)"
      ],
      "metadata": {
        "id": "E-Fw7WBDzX18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loung Attention"
      ],
      "metadata": {
        "id": "eSfQTfeGzbLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ Score(H_{target},H_{source}) = H_{target}^T * W_{combine} * H_{source}$$"
      ],
      "metadata": {
        "id": "gu8BHyqmzc2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.w_combine = tf.keras.layers.Dense(units)\n",
        "\n",
        "    def call(self, h_encoder, h_decoder):\n",
        "        print(\"[h_encoder] shape : \", h_encoder.shape)\n",
        "\n",
        "        wh = self.w_combine(h_encoder)  # Wcombine∗Hsource\n",
        "        print(\"[W_encoder x h_encoder] shape :\", wh.shape)\n",
        "\n",
        "        h_decoder = tf.expand_dims(h_decoder, 1) # 차원 늘리기 \n",
        "        alignment = tf.matmul(wh, tf.transpose(h_decoder,[0,2,1]))  #HTtarget∗Wcombine∗Hsource\n",
        "        print(\"[Score alignment] shape : \", alignment.shape)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(alignment, axis = 1)\n",
        "        print(\"\\n 최종 weight : \\n\", attention_weights.numpy())\n",
        "\n",
        "        attention_weights = tf.squeeze(attention_weights, axis= -1) # 차원 줄이기 \n",
        "        context_vector = tf.matmul(attention_weights, h_encoder)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "UO1Xn8V5zbXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 512\n",
        "attention = LuongAttention(emb_size)\n",
        "\n",
        "enc_state = tf.random.uniform((1, 10, emb_size))\n",
        "dec_state = tf.random.uniform((1, emb_size))\n",
        "\n",
        "_ = attention(enc_state, dec_state)"
      ],
      "metadata": {
        "id": "qd-KxPyKzo5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90991004-20ee-440b-c713-6acf1d146c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[h_encoder] shape :  (1, 10, 256)\n",
            "[W_encoder x h_encoder] shape : (1, 10, 256)\n",
            "[Score alignment] shape :  (1, 10, 1)\n",
            "\n",
            " 최종 weight : \n",
            " [[[4.8733419e-01]\n",
            "  [1.2169003e-01]\n",
            "  [1.3083021e-01]\n",
            "  [2.5176516e-02]\n",
            "  [1.5915568e-03]\n",
            "  [2.5605627e-03]\n",
            "  [9.3482621e-02]\n",
            "  [2.4708272e-03]\n",
            "  [1.3469312e-01]\n",
            "  [1.7037426e-04]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax"
      ],
      "metadata": {
        "id": "wqdIWLCJU8B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "C-sL8U9NU7uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()"
      ],
      "metadata": {
        "id": "jn2ipbLlVB7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_logit = np.array([-2, 1.5, -1, 0.5, 2])\n",
        "pred_prob = softmax(pred_logit)"
      ],
      "metadata": {
        "id": "B31nd5VdVChG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = [18,3])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('predicted logit')\n",
        "plt.bar(np.arange(len(pred_logit)), pred_logit)\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('predicted probility')\n",
        "plt.bar(np.arange(len(pred_prob)), pred_prob)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "sD9cuEX4VTJH",
        "outputId": "80576bf5-c1e4-46bd-8991-3e6cab03bfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}