{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220614 StylegGAN2-ADA 학습.ipynb의 사본의 사본의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juno2856/deeplearning/blob/master/project/StylegGAN2_ADA_%ED%95%99%EC%8A%B5\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show jupyter"
      ],
      "metadata": {
        "id": "rp39m8A9_ypd",
        "outputId": "814ba1b2-dc90-4773-d860-f55801a2b646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: jupyter\n",
            "Version: 1.0.0\n",
            "Summary: Jupyter metapackage. Install all the Jupyter components in one go.\n",
            "Home-page: http://jupyter.org\n",
            "Author: Jupyter Development Team\n",
            "Author-email: jupyter@googlegroups.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: qtconsole, nbconvert, jupyter-console, ipywidgets, notebook, ipykernel\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#로컬 머신에 Jupyer를 설치한다.\n",
        "\n",
        "#주피터 확장 프로그램 설치 및 환경 설정\n",
        "\n",
        "pip install jupyter_http_over_ws\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "\n",
        "\n",
        "#서버 시작 및 인증\n",
        "jupyter notebook \\\n",
        "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
        "  --port=8888 \\\n",
        "  --NotebookApp.port_retries=0\n",
        "\n",
        "#로컬 런타임 연결\n",
        "#Colaboratory에서 '연결' 버튼을 클릭하고 '로컬 런타임에 연결...'을 선택한다."
      ],
      "metadata": {
        "id": "XpJeVI2mpGD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ji34iSuOpF_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "848Zax-CpF8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fN-d1-N9s0"
      },
      "source": [
        "# StyleGAN2-ADA 모델 학습하기\n",
        "\n",
        "이 노트북은 다음 노트북을 합쳐서 만들고 한글 설명을 추가했습니다.\n",
        "\n",
        "- https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Stylegan2_ada_Custom_Training.ipynb\n",
        "- https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFB64iL9BzBd"
      },
      "source": [
        "StyleGAN2-ADA 모델은 텐서플로우 1 버전에서만 작동합니다. 아래 셀을 실행해서 1 버전을 사용할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbyUpDO4OLiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32456ec1-c9b2-4a07-cb26-47b082a50e48"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pip install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "pGX_fPVGwmre",
        "outputId": "537113f6-83e9-4a39-ccad-d356fbbe2d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 7.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91s4Bdk2CAJi"
      },
      "source": [
        "현재 구글에서 어떤 GPU를 할당받았는지 알아봅니다. 노트북 위의 메뉴에서 Runtime > Change runtime type 으로 가서 GPU가 선택되었는지 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiBLUTr7OVoB",
        "outputId": "592f4f8e-e4b0-41fe-fbde-a6b5393e3744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  4 00:35:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhGEeUh8CEMc"
      },
      "source": [
        "내 구글 계정의 드라이브를 이 노트북과 연동시킵니다. 앞으로는 구글 드라이브의 파일을 노트북에서 가져다쓰거나, 노트북에서 생성된 파일들을 내 드라이브로 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F46YSLmVOWWa",
        "outputId": "dd798b7b-f1ab-4d9a-89e7-28927f3d7800"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1jG7Cx1RWKY"
      },
      "source": [
        "## Clone StyleGAN2-ADA Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDEl_QC6CbDr"
      },
      "source": [
        "StyleGAN2-ADA 관련된 코드를 노트북으로 불러와서 다운로드받습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVtHBVKbOmKl",
        "outputId": "2cc2eca9-7287-4ca3-b996-a573305b768d"
      },
      "source": [
        "# Download the code\n",
        "%cd /content/\n",
        "!git clone https://github.com/dvschultz/stylegan2-ada.git\n",
        "!mkdir downloads\n",
        "!mkdir datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Total 364 (delta 0), reused 0 (delta 0), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (364/364), 56.17 MiB | 31.30 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffxQiIkQRTGO"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa5ILnoJXNXq"
      },
      "source": [
        "이번 노트북에서 학습에 사용할 데이터는 포켓몬 이미지 데이터입니다. 다음 링크에서 다운로드받을 수 있습니다:\n",
        "\n",
        "https://www.kaggle.com/kvpratama/pokemon-images-dataset\n",
        "\n",
        "다운로드받은 파일은 각자의 구글 드라이브 폴더에 미리 업로드시켜주세요. 업로드한 후에는, 이 노트북에서 데이터를 불러와서 학습에 사용할 수 있습니다. 여기서는 포켓몬 데이터셋 (256x256)을 사용하지만, 다른 데이터셋으로 학습도 가능합니다.\n",
        "\n",
        "데이터셋의 이름을 zip파일 이름으로 바꿔주세요:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w637CVdoO3du"
      },
      "source": [
        "dataset_name = \"id_dataset_ada\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NKBXJsUC1Cc"
      },
      "source": [
        "노트북으로 데이터셋 압축파일을 불러와서 압축을 풉니다. 왼쪽 Files에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "_tdy-VknQbkW",
        "outputId": "350ca09f-6a67-4430-f317-fd29f69d9cfb"
      },
      "source": [
        "import zipfile\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "dataset = dataset_name + \".zip\"\n",
        "local_path = \"/content/\"\n",
        "file_name = path + dataset\n",
        "with zipfile.ZipFile(file_name, 'r') as zip:\n",
        "   #zip.printdir()\n",
        "   print('Extracting all the files now...') \n",
        "   zip.extractall(local_path) \n",
        "   print('Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-603e4fbd811f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlocal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m#zip.printdir()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting all the files now...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/id_dataset_ada.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxtOLRCvDULH"
      },
      "source": [
        "불러온 이미지 데이터셋 jpg 파일들을 텐서플로에서 사용할 수 있는 데이터셋 포맷(tfrecords)으로 바꿔줍니다. 이 변환과정이 데이터셋의 크기에 따라 굉장히 오래 걸릴 수 있습니다. 이미지 파일들이 저장되어있는 경로를 잘 설정해줘야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlS7sB4xQtmC",
        "outputId": "6f4e2857-5976-4643-ebb5-d82e9c430568"
      },
      "source": [
        "%cd /content/drive/MyDrive/final/\n",
        "\n",
        "#update this to the path to your image folder\n",
        "dataset_folder_name = 'id_body256' # name of zip file may be different from folder name it extracted to\n",
        "dataset_path = \"/content/drive/MyDrive/final/\" + dataset_folder_name\n",
        "\n",
        "#you don't need to edit anything here\n",
        "%cd /content/stylegan2-ada\n",
        "!python dataset_tool.py create_from_images /content/datasets/{dataset_name} {dataset_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/final\n",
            "/content/stylegan2-ada\n",
            "Loading images from \"/content/drive/MyDrive/final/id_body256\"\n",
            "Creating dataset \"/content/datasets/id_dataset_ada\"\n",
            "dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 1207 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhe_tggRPnq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrikBYS-VOnO"
      },
      "source": [
        "학습할 때 우리가 조절할 수 있는 다양한 패러미터들이 있습니다. 다음 셀을 실행하면 도움말을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPPicfQXQ_PZ",
        "outputId": "785d1857-9846-4bf2-fafc-deb27469e61d"
      },
      "source": [
        "%cd /content/stylegan2-ada\n",
        "!python train.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n",
            "usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n",
            "                --data PATH [--res INT] [--mirror BOOL] [--mirrory BOOL]\n",
            "                [--use-raw BOOL] [--metrics LIST] [--metricdata PATH]\n",
            "                [--cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}]\n",
            "                [--lrate FLOAT] [--ttur BOOL] [--gamma FLOAT] [--nkimg INT]\n",
            "                [--kimg INT] [--topk FLOAT] [--aug {noaug,ada,fixed,adarv}]\n",
            "                [--p FLOAT] [--target TARGET] [--initstrength INITSTRENGTH]\n",
            "                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n",
            "                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n",
            "                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n",
            "\n",
            "Train a GAN using the techniques described in the paper\n",
            "\"Training Generative Adversarial Networks with Limited Data\".\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "\n",
            "general options:\n",
            "  --outdir DIR          Where to save the results (required)\n",
            "  --gpus INT            Number of GPUs to use (default: 1 gpu)\n",
            "  --snap INT            Snapshot interval (default: 50 ticks)\n",
            "  --seed INT            Random seed (default: 1000)\n",
            "  -n, --dry-run         Print training options and exit\n",
            "\n",
            "training dataset:\n",
            "  --data PATH           Training dataset path (required)\n",
            "  --res INT             Dataset resolution (default: highest available)\n",
            "  --mirror BOOL         Augment dataset with x-flips (default: false)\n",
            "  --mirrory BOOL        Augment dataset with y-flips (default: false)\n",
            "  --use-raw BOOL        Use raw image dataset, i.e. created from\n",
            "                        create_from_images_raw (default: False)\n",
            "\n",
            "metrics:\n",
            "  --metrics LIST        Comma-separated list or \"none\" (default: fid50k_full)\n",
            "  --metricdata PATH     Dataset to evaluate metrics against (optional)\n",
            "\n",
            "base config:\n",
            "  --cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}\n",
            "                        Base config (default: auto)\n",
            "  --lrate FLOAT         Override learning rate\n",
            "  --ttur BOOL           Use Two Time-Scale Update Rule (double learning rate\n",
            "                        for discriminator) (default: false)\n",
            "  --gamma FLOAT         Override R1 gamma\n",
            "  --nkimg INT           Override starting count\n",
            "  --kimg INT            Override training duration\n",
            "  --topk FLOAT          utilize top-k training\n",
            "\n",
            "discriminator augmentation:\n",
            "  --aug {noaug,ada,fixed,adarv}\n",
            "                        Augmentation mode (default: ada)\n",
            "  --p FLOAT             Specify augmentation probability for --aug=fixed\n",
            "  --target TARGET       Override ADA target for --aug=ada and --aug=adarv\n",
            "  --initstrength INITSTRENGTH\n",
            "                        Override ADA strength at start\n",
            "  --augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}\n",
            "                        Augmentation pipeline (default: bgc)\n",
            "\n",
            "comparison methods:\n",
            "  --cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}\n",
            "                        Comparison method (default: nocmethod)\n",
            "  --dcap FLOAT          Multiplier for discriminator capacity\n",
            "\n",
            "transfer learning:\n",
            "  --resume RESUME       Resume from network pickle (default: noresume)\n",
            "  --freezed INT         Freeze-D (default: 0 discriminator layers)\n",
            "\n",
            "examples:\n",
            "\n",
            "  # Train custom dataset using 1 GPU.\n",
            "  python train.py --outdir=~/training-runs --gpus=1 --data=~/datasets/custom\n",
            "\n",
            "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
            "  python train.py --outdir=~/training-runs --gpus=2 --data=~/datasets/cifar10c \\\n",
            "      --cfg=cifar\n",
            "\n",
            "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
            "  python train.py --outdir=~/training-runs --gpus=4 --data=~/datasets/metfaces \\\n",
            "      --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
            "\n",
            "  # Reproduce original StyleGAN2 config F.\n",
            "  python train.py --outdir=~/training-runs --gpus=8 --data=~/datasets/ffhq \\\n",
            "      --cfg=stylegan2 --res=1024 --mirror=1 --aug=noaug\n",
            "\n",
            "available base configs (--cfg):\n",
            "  auto           Automatically select reasonable defaults based on resolution\n",
            "                 and GPU count. Good starting point for new datasets.\n",
            "  stylegan2      Reproduce results for StyleGAN2 config F at 1024x1024.\n",
            "  paper256       Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
            "  paper512       Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
            "  paper1024      Reproduce results for MetFaces at 1024x1024.\n",
            "  cifar          Reproduce results for CIFAR-10 (tuned configuration).\n",
            "  cifarbaseline  Reproduce results for CIFAR-10 (baseline configuration).\n",
            "\n",
            "transfer learning source networks (--resume):\n",
            "  ffhq256        FFHQ trained at 256x256 resolution.\n",
            "  ffhq512        FFHQ trained at 512x512 resolution.\n",
            "  ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
            "  celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
            "  lsundog256     LSUN Dog trained at 256x256 resolution.\n",
            "  afhqcat512     AFHQ Cat trained at 512x512 resolution.\n",
            "  afhqdog512     AFHQ Dog trained at 512x512 resolution.\n",
            "  afhqwild512    AFHQ Wild trained at 512x512 resolution.\n",
            "  brecahad512    BreCaHAD trained at 512x512 resolution.\n",
            "  cifar10        CIFAR10 trained at 32x32 resolution.\n",
            "  metfaces512    MetFaces trained at 512x512 resolution.\n",
            "  <path or URL>  Custom network pickle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlt3UUwVWmg"
      },
      "source": [
        "아래 셀을 실행하면 학습이 시작됩니다. **학습이 진행되는 동안에는, 이 노트북 창을 열어두어야 합니다.** 노트북 창을 닫거나 인터넷 연결이 끊기면, 콜랩 노트북의 실행이 중단됩니다. 또, 너무 오랜시간동안 실행되고 있는 노트북은 구글에서 자동으로 차단합니다. 연결이 끊긴 경우에는 이 노트북을 처음 셀부터 다시 실행해야합니다. 연결이 끊긴 후에 이어서 학습을 하고 싶은 경우에는 `resume_from` 경로를 최근의 `pkl` 파일 경로로 바꿔주세요.\n",
        "\n",
        "학습이 진행되는 동안 구글 드라이브 폴더를 확인해보세요. 중간 과정의 이미지 결과물과 모델을 자동으로 저장합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo53TCYVRKW0",
        "outputId": "86ba5f58-16a4-4c2f-c4be-5d59903380e9"
      },
      "source": [
        "# output directory\n",
        "output_dir = '/content/drive/MyDrive/results/' + dataset_name + \"/\"\n",
        "\n",
        "# config\n",
        "config = \"auto\"\n",
        "\n",
        "# gamma\n",
        "gamma = 1\n",
        "\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 1\n",
        "\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#\n",
        "# this is the most important cell to update\n",
        "#\n",
        "# running it for the first time? set it to ffhq(+resolution)\n",
        "# resuming? get the path to your latest .pkl file and use that\n",
        "# resume_from = \"ffhq256\"\n",
        "\n",
        "# make sure there is no space in the resume path. if there is any, use a backslash character to escape\n",
        "resume_from = '/content/drive/MyDrive/results/id_dataset_ada/00010-id_dataset_ada-mirror-auto1-gamma1-resumecustom/network-snapshot-000000.pkl'\n",
        "\n",
        "#don't edit this unless you know what you're doing :)\n",
        "!python train.py --outdir={output_dir} \\\n",
        "                 --cfg={config} \\\n",
        "                 --snap={snapshot_count} \\\n",
        "                 --data=/content/datasets/{dataset_name} \\\n",
        "                 --mirror={mirrored} --mirrory={mirroredY} \\\n",
        "                 --gamma={gamma} \\\n",
        "                 --metrics={metric_list} \\\n",
        "                 --resume={resume_from}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 4294967296 bytes == 0x719c000 @  0x7fd87c3bb001 0x7fd8795bf54f 0x7fd87960fb58 0x7fd879613b17 0x7fd8796b2203 0x593835 0x548c51 0x5127f1 0x549e0e 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x4bca8a 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fd6abece000 @  0x7fd87c3b91e7 0x7fd8795bf46e 0x7fd87960fc7b 0x7fd87961035f 0x7fd8796b2103 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fd5aaecc000 @  0x7fd87c3b91e7 0x7fd8795bf46e 0x7fd87960fc7b 0x7fd87961035f 0x7fd8361db235 0x7fd835b5e792 0x7fd835b5ed42 0x7fd835b17aee 0x59371f 0x548c51 0x51566f 0x593dd7 0x511e2c 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5134a6 0x549576 0x593fce\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 8192,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 8192,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 1.0\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/datasets/id_dataset_ada\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 256,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/datasets/id_dataset_ada\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 256,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"minibatch_size\": 16,\n",
            "  \"minibatch_gpu\": 16,\n",
            "  \"G_smoothing_kimg\": 5.0,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/results/id_dataset_ada/00010-id_dataset_ada-mirror-auto1-gamma1-resumecustom/network-snapshot-000000.pkl\",\n",
            "  \"run_dir\": \"/content/drive/MyDrive/results/id_dataset_ada/00011-id_dataset_ada-mirror-auto1-gamma1-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/MyDrive/results/id_dataset_ada/00011-id_dataset_ada-mirror-auto1-gamma1-resumecustom\n",
            "Training data:     /content/datasets/id_dataset_ada\n",
            "Training length:   25000 kimg\n",
            "Resolution:        256\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x719c000 @  0x7fd87c3bb001 0x7fd8795bf54f 0x7fd87960fb58 0x7fd879613b17 0x7fd8796b2203 0x593835 0x548c51 0x5127f1 0x549e0e 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x4bca8a 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fd49f678000 @  0x7fd87c3b91e7 0x7fd8795bf46e 0x7fd87960fc7b 0x7fd87961035f 0x7fd8796b2103 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fd49f678000 @  0x7fd87c3b91e7 0x7fd8795bf46e 0x7fd87960fc7b 0x7fd87961035f 0x7fd8361db235 0x7fd835b5e792 0x7fd835b5ed42 0x7fd835b17aee 0x59371f 0x548c51 0x51566f 0x593dd7 0x511e2c 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5134a6 0x549576 0x593fce\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
            "Resuming from \"/content/drive/MyDrive/results/id_dataset_ada/00010-id_dataset_ada-mirror-auto1-gamma1-resumecustom/network-snapshot-000000.pkl\"\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "epochs                        1         ()                  ()              \n",
            "epochs_1                      1         ()                  ()              \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "Truncation/Lerp               -         (?, 14, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
            "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
            "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
            "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
            "G_synthesis/256x256/Conv0_up  139457    (?, 64, 256, 256)   (3, 3, 128, 64) \n",
            "G_synthesis/256x256/Conv1     69761     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     33027     (?, 3, 256, 256)    (1, 1, 64, 3)   \n",
            "---                           ---       ---                 ---             \n",
            "Total                         23191524                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 256, 256)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "256x256/FromRGB      256       (?, 64, 256, 256)   (1, 1, 3, 64)   \n",
            "256x256/Conv0        36928     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
            "256x256/Conv1_down   73856     (?, 128, 128, 128)  (3, 3, 64, 128) \n",
            "256x256/Skip         8192      (?, 128, 128, 128)  (1, 1, 64, 128) \n",
            "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
            "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
            "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
            "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
            "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
            "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "---                  ---       ---                 ---             \n",
            "Total                24001089                                      \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      time 1m 17s       sec/tick 22.7    sec/kimg 354.83  maintenance 54.7   gpumem 7.2   augment 0.001\n",
            "tick 1     kimg 4.1      time 6m 52s       sec/tick 317.7   sec/kimg 78.80   maintenance 17.2   gpumem 7.2   augment 0.029\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RPx51K6STGFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}